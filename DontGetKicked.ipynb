{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't Get Kicked\n",
    "\n",
    "Here, we are trying to predict used cars purchases which incur loss to dealerships. First, we need to load the data. Then, we concatenate two dataframes to do some feature engineering on the entire dataset.\n",
    "\n",
    "In this section we load the necessary libraries and write functions to process data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# Data preprocessing and feature engineering\n",
    "def preprocessing(train_df, test_df):\n",
    "    data_train = pd.read_csv('training.csv')\n",
    "    data_test = pd.read_csv('test.csv')\n",
    "    \n",
    "    y_train = data_train[\"IsBadBuy\"]\n",
    "    \n",
    "    data_train = data_train.drop([\"IsBadBuy\"], axis = 1)\n",
    "    \n",
    "    print(\"The size of training data is:\", len(data_train))\n",
    "    print(\"The size of test data is:\", len(data_test))\n",
    "    \n",
    "    print('The number of cars in Good/Kick classes are, respectively: ', Counter(y_train))\n",
    "\n",
    "\n",
    "    data = pd.concat([data_train, data_test])\n",
    "\n",
    "    data[\"PurchYear\"] = data[\"PurchDate\"].apply(lambda x: x.split(\"/\")[2]).astype(int)\n",
    "    data[\"PurchMonth\"] = data[\"PurchDate\"].apply(lambda x: x.split(\"/\")[0]).astype(int)\n",
    "    data = data.drop(['PurchDate'], axis=1)\n",
    "\n",
    "    data[\"AUCGUART\"] = data[\"AUCGUART\"].fillna(\"YELLOW\")\n",
    "\n",
    "    cat_cols = ['Auction', 'Make', 'Model', 'Trim', 'SubModel', 'Color', 'Transmission', 'WheelType', \n",
    "                'Nationality', 'Size', 'TopThreeAmericanName', 'PRIMEUNIT', 'AUCGUART', 'VNST']\n",
    "\n",
    "    for col in cat_cols:\n",
    "        data[col] = data[col].fillna(data[col].mode()[0])\n",
    "\n",
    "    for col in list(data):\n",
    "        if col not in cat_cols:\n",
    "            data[col] = data[col].fillna(data[col].median())\n",
    "        \n",
    "        \n",
    "        \n",
    "    data[\"MMR\"] = data[['MMRAcquisitionAuctionAveragePrice', 'MMRAcquisitionRetailAveragePrice',\n",
    "                        'MMRCurrentAuctionAveragePrice', 'MMRCurrentRetailAveragePrice', \n",
    "                        'MMRAcquisitionAuctionCleanPrice', 'MMRAcquisitonRetailCleanPrice',\n",
    "                        'MMRCurrentAuctionCleanPrice', 'MMRCurrentRetailCleanPrice']].mean(axis=1)\n",
    "\n",
    "\n",
    "    data[\"VehicleAge\"] = data[\"VehicleAge\"].replace(to_replace = 0, value = 0.1)\n",
    "    data[\"MilesperYear\"] = data[\"VehOdo\"] / data[\"VehicleAge\"]\n",
    "\n",
    "    data[\"WheelTypeID\"] = data[\"WheelTypeID\"].replace(to_replace = 0, value = 1)\n",
    "    data[\"Transmission\"] = data[\"Transmission\"].replace(to_replace = \"Manual\", value = \"MANUAL\")\n",
    "\n",
    "    del_col = ['RefId', 'VehYear', 'SubModel', 'WheelType', 'VehOdo',\n",
    "               'MMRAcquisitionAuctionAveragePrice', 'MMRAcquisitionAuctionCleanPrice',\n",
    "               'MMRAcquisitionRetailAveragePrice', 'MMRAcquisitonRetailCleanPrice',\n",
    "               'MMRCurrentAuctionAveragePrice', 'MMRCurrentAuctionCleanPrice',\n",
    "               'MMRCurrentRetailAveragePrice', 'MMRCurrentRetailCleanPrice']\n",
    "\n",
    "    for col in del_col:\n",
    "        data = data.drop([col], axis = 1)\n",
    "\n",
    "    \n",
    "    # Encoding categorical data\n",
    "    labelencoder = LabelEncoder()\n",
    "\n",
    "    data[['Transmission']] = labelencoder.fit_transform(data[['Transmission']])\n",
    "    data[['PRIMEUNIT']] = labelencoder.fit_transform(data[['PRIMEUNIT']])\n",
    "\n",
    "    data = pd.get_dummies(data, columns = ['Auction', 'Make', 'Model', 'Trim', 'Color', 'Nationality', \n",
    "                                           'Size', 'TopThreeAmericanName', 'AUCGUART', 'VNST'])\n",
    "\n",
    "\n",
    "    Class_0_ix = np.random.choice(y_train[y_train==0].index.tolist(), size=9024).tolist()\n",
    "\n",
    "    ix = y_train[y_train==1].index.tolist() + Class_0_ix\n",
    "    \n",
    "    train = data.iloc[ix]\n",
    "    y_train = y_train.iloc[ix]\n",
    "    test = data.iloc[72983:]\n",
    "    \n",
    "    print('The number of cars in Good/Kick classes after down-sampling of the former are, respectively: ', Counter(y_train))\n",
    "\n",
    "    return [train, y_train, test, data_test]\n",
    "    \n",
    "    \n",
    "\n",
    "# Apply PCA to remove overlapping data\n",
    "def apply_pca(train_df, test_df, n_features):\n",
    "\n",
    "    pca = PCA(n_components=n_features)\n",
    "    pca.fit(np.array(train_df))\n",
    "\n",
    "    train_df_pca = pca.transform(train_df)\n",
    "\n",
    "    test_df_pca = pca.transform(test_df)\n",
    "    \n",
    "    return [train_df_pca, test_df_pca]\n",
    "\n",
    "\n",
    "# Evaluation and Score\n",
    "def gini(actual, pred):\n",
    "\n",
    "    actual_len = len(actual)\n",
    "    assert( actual_len == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(actual_len) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ] \n",
    "    giniSum = all[:,0].cumsum().sum() / all[:,0].sum()\n",
    "    giniSum -= (actual_len + 1) / 2.\n",
    "    return giniSum / actual_len\n",
    "\n",
    "def normalized_gini(solution, submission):\n",
    "    normalized_gini = gini(solution, submission)/gini(solution, solution)\n",
    "    return normalized_gini\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the functions above, the data is loaded and preprocessed as follows. One may extract the month and year of purchase and ignore the rest of this column, since the type of this column is string. Next, we need to fill the missing data. The \"AUCGUART\" column is filled with \"YELLOW\", since the majority of the data in this column is missing and this value is an intermediate value. For other categorical features we use the mode and for numerical data the missing values are replaced with the median of the column. The data related to MMR can be condensed to just one column showing the average of all MMRs. Moreover, the \"VehOdo\" column can be replaced by \"Miles per Year\".\n",
    "\n",
    "We encode all categorical features and one hot encode those with more than two non-ordinal categories. Besides, the Kicked/Good class is skewed and can cause issues for the predictive model. One method to fix issue is to downsize the dominent class, so that the size of two classes are close to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of training data is: 72983\n",
      "The size of test data is: 48707\n",
      "The number of cars in Good/Kick classes are, respectively:  Counter({0: 64007, 1: 8976})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of cars in Good/Kick classes after down-sampling of the former are, respectively:  Counter({0: 9024, 1: 8976})\n"
     ]
    }
   ],
   "source": [
    "[train, y_train, test, data_test] = preprocessing('training.csv', 'test.csv')\n",
    "\n",
    "\n",
    "# Apply PCA\n",
    "[train_pca, test_pca] = apply_pca(train, test, n_features=200)\n",
    "\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_pca, y_train, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a model has to be selected to learn from the training data set and predict the class associated with each car in the test data. The XGBoost model is selected here, however, we need to investigate more models and compare the results based on the CV scores. We generate a csv file as the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The normalized Gini coefficient is:  0.2990780762918337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# parameter tuning of xgboost\n",
    "# start from default setting\n",
    "boost_params = {'eval_metric': 'logloss'}\n",
    "\n",
    "classifier = XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=100,\n",
    "                           silent=True, objective=\"binary:logistic\", booster='gbtree',\n",
    "                           n_jobs=-1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0,\n",
    "                           subsample=1, colsample_bytree=1, colsample_bylevel=1, reg_alpha=0,\n",
    "                           reg_lambda=1, scale_pos_weight=1, base_score=0.5)\n",
    "                  \n",
    "\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies.mean()\n",
    "accuracies.std()\n",
    "\n",
    "\n",
    "\"\"\"# Applying Grid Search to find the best model and the best parameters\n",
    "parameters = [{'max_depth': [2, 3, 4, 5], 'learning_rate': [0.5, .1, .01, .001], 'n_estimators': [10, 100, 1000],\n",
    "              'gamma': [0, .1, .2, .3], 'min_child_weight': [1, 3, 7, 10]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(best_parameters)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#gini(y_test, y_pred)\n",
    "print('The normalized Gini coefficient is: ', normalized_gini(y_test, y_pred))\n",
    "\n",
    "# The trained model is used to predict the class of each car:\n",
    "data_test['IsBadBuy'] = classifier.predict(test_pca)\n",
    "\n",
    "data_test[['RefId', 'IsBadBuy']].to_csv(\n",
    "    'kick_submission.csv', index=False, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gini coefficient or the normalized Gini coefficient are appropriate choices to quantify the classification performance. We ideally look for maximizing the true positive and true negative, and minimize false negative and false positive. A confusion matrix can help us see the number of cars in each category. Alternatively, a F1-score can be used, which is a metric to evaluate precision and recall.\n",
    "\n",
    "In order to improve the performance of the model, we can make one of the following changes:\n",
    "- The number of \"Good\" cars can be increased or decreased. Also, we can try another technique to address the skewed class, for example over-sampling the \"Kicked\" cars.\n",
    "- The number of final featuers in PCA can be increased.\n",
    "- The hyper parameters in XGBoost can be tuned using grid search (commented in the last cell).\n",
    "- Another machine leaning technique can be adopted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
